{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09_text_classification.ipynb のコピー","provenance":[{"file_id":"1iAE2OUx7nFZzyrasJMYGf8fxd_fO80t7","timestamp":1620031857805},{"file_id":"1OkBqBVZ7X-9eG76Dua-SVp5Fy4xwtJO0","timestamp":1579656877473}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"29b19a3346fa4dd4a7bb38019f68c9e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_805aa5e2b54b47d3a6bc8623e574a537","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a53b67a544a4c0c97e73aac5421a765","IPY_MODEL_8c3aa17454d84735a7e6ce14f597cb87"]}},"805aa5e2b54b47d3a6bc8623e574a537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a53b67a544a4c0c97e73aac5421a765":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fb65578483cc40759b7142dfcbbb59a0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c1a33d021be47c5b1523f779eb883ad"}},"8c3aa17454d84735a7e6ce14f597cb87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c6879b35a914dcab1eb86d37afeab5b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 10.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2702df0925684744a797675858e5ccea"}},"fb65578483cc40759b7142dfcbbb59a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4c1a33d021be47c5b1523f779eb883ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c6879b35a914dcab1eb86d37afeab5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2702df0925684744a797675858e5ccea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42e909f5e7b74256943e41efa2e81121":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afe43cd045ee4073989772209638ffd3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c96aea443b141b59c3291d8fd7294c6","IPY_MODEL_f3b0fb87c01b4019a2446275824b5291"]}},"afe43cd045ee4073989772209638ffd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c96aea443b141b59c3291d8fd7294c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d53bf36fc58e44ebb4a0be781f2d5101","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":257706,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":257706,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_045b231a90a0481ea801d2b912c2881b"}},"f3b0fb87c01b4019a2446275824b5291":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da695a6594b74efc9a251da947950ae7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 258k/258k [00:00&lt;00:00, 664kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0a5036ea5d542a28a5db4ed4f8cb2bf"}},"d53bf36fc58e44ebb4a0be781f2d5101":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"045b231a90a0481ea801d2b912c2881b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da695a6594b74efc9a251da947950ae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0a5036ea5d542a28a5db4ed4f8cb2bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4dbea13effa4c13a4b710ac6de5d756":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bff74540d6dd49d8a7e1765b25f00264","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_59ca4fbc8ec84e968fe5b325ced021ea","IPY_MODEL_6e136d2fda5b404383fe06704e65001f"]}},"bff74540d6dd49d8a7e1765b25f00264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59ca4fbc8ec84e968fe5b325ced021ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_599900a96f0444bbb86de5e575aca1b4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":545149952,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":545149952,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af80f911e42249c0bd38b83c71f59b87"}},"6e136d2fda5b404383fe06704e65001f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5cc588537ba3409082b2beb383aef7b5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 545M/545M [00:14&lt;00:00, 36.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2109d4004fa34b16bf4670d07bf8f7b3"}},"599900a96f0444bbb86de5e575aca1b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af80f911e42249c0bd38b83c71f59b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cc588537ba3409082b2beb383aef7b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2109d4004fa34b16bf4670d07bf8f7b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"nsnhYVPtvJ1P"},"source":["# Text Classification with Deep Learning\n","\n","## History\n","\n","### 2020/11/3\n","\n","- Explain how to fine-tune BERT for text classification with ktrain\n","- Change `weights` to `embeddings_initializer`\n","- Call `clear_session()` when creating models in a loop to avoid OOM\n","\n","**References**\n","- [Using pre-trained word embeddings | version: Last modified: 2020/05/05](https://keras.io/examples/nlp/pretrained_word_embeddings/)\n","- [tf.keras.backend.clear_session\n","](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session)"]},{"cell_type":"markdown","metadata":{"id":"wkDOfRY-iGa6"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"MLS_APoueTC8"},"source":["%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBYtpv8ZeXsX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604628432945,"user_tz":-540,"elapsed":20527,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"105f64a9-31ca-4b3c-b5ff-648770b0f689"},"source":["!pip install janome beautifulsoup4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting janome\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n","\u001b[K     |████████████████████████████████| 19.7MB 72.6MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n","Installing collected packages: janome\n","Successfully installed janome-0.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nZMUsGqQec6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604399682650,"user_tz":-540,"elapsed":5332,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"30737dc8-7771-47f1-b876-b4c23bd6c425"},"source":["!mkdir data\n","!mkdir models\n","!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz -P data/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘data’: File exists\n","mkdir: cannot create directory ‘models’: File exists\n","--2020-11-03 10:34:40--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1279641604 (1.2G) [binary/octet-stream]\n","Saving to: ‘data/cc.ja.300.vec.gz.1’\n","\n","cc.ja.300.vec.gz.1    0%[                    ]  11.34M  11.6MB/s               ^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WwGX88rvEO4l"},"source":["### Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"hIIwk_n3EVqO"},"source":["maxlen = 300\n","num_words = 40000\n","num_label = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tn2IFMP9vVCM"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"2YGTG_tXvZCe"},"source":["import string\n","\n","import gensim\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from bs4 import BeautifulSoup\n","from janome.tokenizer import Tokenizer\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.layers import Dense, Input, Embedding, SimpleRNN, LSTM, Conv1D, GlobalMaxPooling1D\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubOwS_mfh4Bu"},"source":["## The dataset"]},{"cell_type":"markdown","metadata":{"id":"8ngFa4k4wAt3"},"source":["### Load the Amazon Customer Reviews Datasets"]},{"cell_type":"code","metadata":{"id":"NldWkmWqg3eD"},"source":["def filter_by_ascii_rate(text, threshold=0.9):\n","    ascii_letters = set(string.printable)\n","    rate = sum(c in ascii_letters for c in text) / len(text)\n","    return rate <= threshold\n","\n","\n","def load_dataset(filename, n=5000):\n","    df = pd.read_csv(filename, sep='\\t')\n","\n","    # Converts multi-class to binary-class.\n","    mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","    df = df[df.star_rating != 3]\n","    df.star_rating = df.star_rating.map(mapping)\n","\n","    # extracts Japanese texts.\n","    is_jp = df.review_body.apply(filter_by_ascii_rate)\n","    df = df[is_jp]\n","\n","    # sampling.\n","    df = df.sample(frac=1, random_state=7)  # shuffle\n","    grouped = df.groupby('star_rating')\n","    df = grouped.head(n=n)\n","    return df.review_body.values, df.star_rating.values\n","\n","\n","url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz'\n","x, y = load_dataset(url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1cLWKlqpwoeL"},"source":["### Load the word embeddings"]},{"cell_type":"code","metadata":{"id":"md9Iun1fwrTI"},"source":["def load_fasttext(filepath, binary=False):\n","    \"\"\"Loads fastText vectors.\n","\n","    Args:\n","        filepath (str): a path to a fastText file.\n","\n","    Return:\n","        model: KeyedVectors\n","    \"\"\"\n","    model = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=binary)\n","    return model\n","\n","\n","wv = load_fasttext('data/cc.ja.300.vec.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jYdugMjzh8yz"},"source":["### Preprocess the dataset"]},{"cell_type":"code","metadata":{"id":"RWlQYG-phz0n"},"source":["t = Tokenizer(wakati=True)\n","\n","\n","def build_vocabulary(texts, num_words=None):\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        num_words=num_words, oov_token='<UNK>'\n","    )\n","    tokenizer.fit_on_texts(texts)\n","    return tokenizer\n","\n","\n","def clean_html(html, strip=False):\n","    soup = BeautifulSoup(html, 'html.parser')\n","    text = soup.get_text(strip=strip)\n","    return text\n","\n","\n","def tokenize(text):\n","    return t.tokenize(text)\n","\n","\n","def preprocess_dataset(texts):\n","    texts = [clean_html(text) for text in texts]\n","    texts = [' '.join(tokenize(text)) for text in texts]\n","    return texts\n","\n","\n","def filter_embeddings(embeddings, vocab, num_words, dim=300):\n","  \"\"\"Filter word vectors.\n","\n","  Args:\n","      embeddings: a dictionary like object.\n","      vocab: word-index lookup table.\n","      num_words: the number of words.\n","      dim: dimension.\n","\n","  Returns:\n","      numpy array: an array of word embeddings.\n","  \"\"\"\n","  _embeddings = np.zeros((num_words, dim))\n","  for word in vocab:\n","      if word in embeddings:\n","          word_id = vocab[word]\n","          if word_id >= num_words:\n","              continue\n","          _embeddings[word_id] = embeddings[word]\n","\n","  return _embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XG7xi7LYFTMs"},"source":["x = preprocess_dataset(x)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","vocab = build_vocabulary(x_train, num_words)\n","x_train = vocab.texts_to_sequences(x_train)\n","x_test = vocab.texts_to_sequences(x_test)\n","x_train = pad_sequences(x_train, maxlen=maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen=maxlen, truncating='post', padding='post')\n","\n","wv = filter_embeddings(wv, vocab.word_index, num_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49qdjUsFurRX"},"source":["## The models"]},{"cell_type":"markdown","metadata":{"id":"RodOCCr2wfHu"},"source":["### Build the models"]},{"cell_type":"code","metadata":{"id":"vSORC-J0usu4"},"source":["class RNNModel:\n","\n","    def __init__(self, input_dim, output_dim,\n","                 emb_dim=300, hid_dim=100,\n","                 embeddings=None, trainable=True):\n","        self.input = Input(shape=(None,), name='input')\n","        if embeddings is None:\n","            self.embedding = Embedding(input_dim=input_dim,\n","                                       output_dim=emb_dim,\n","                                       mask_zero=True,\n","                                       trainable=trainable,\n","                                       name='embedding')\n","        else:\n","            self.embedding = Embedding(input_dim=embeddings.shape[0],\n","                                       output_dim=embeddings.shape[1],\n","                                       mask_zero=True,\n","                                       trainable=trainable,\n","                                       embeddings_initializer=tf.keras.initializers.Constant(embeddings),\n","                                       # weights=[embeddings],\n","                                       name='embedding')\n","        self.rnn = SimpleRNN(hid_dim, name='rnn')\n","        self.fc = Dense(output_dim, activation='softmax')\n","\n","    def build(self):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        output = self.rnn(embedding)\n","        y = self.fc(output)\n","        return Model(inputs=x, outputs=y)\n","\n","\n","class LSTMModel:\n","\n","    def __init__(self, input_dim, output_dim,\n","                 emb_dim=300, hid_dim=100,\n","                 embeddings=None, trainable=True):\n","        self.input = Input(shape=(None,), name='input')\n","        if embeddings is None:\n","            self.embedding = Embedding(input_dim=input_dim,\n","                                       output_dim=emb_dim,\n","                                       mask_zero=True,\n","                                       trainable=trainable,\n","                                       name='embedding')\n","        else:\n","            self.embedding = Embedding(input_dim=embeddings.shape[0],\n","                                       output_dim=embeddings.shape[1],\n","                                       mask_zero=True,\n","                                       trainable=trainable,\n","                                       embeddings_initializer=tf.keras.initializers.Constant(embeddings),\n","                                       # weights=[embeddings],\n","                                       name='embedding')\n","        self.lstm = LSTM(hid_dim, name='lstm')\n","        self.fc = Dense(output_dim, activation='softmax')\n","\n","    def build(self):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        output = self.lstm(embedding)\n","        y = self.fc(output)\n","        return Model(inputs=x, outputs=y)\n","\n","\n","class CNNModel:\n","\n","    def __init__(self, input_dim, output_dim,\n","                 filters=250, kernel_size=3,\n","                 emb_dim=300, embeddings=None, trainable=True):\n","        self.input = Input(shape=(None,), name='input')\n","        if embeddings is None:\n","            self.embedding = Embedding(input_dim=input_dim,\n","                                       output_dim=emb_dim,\n","                                       trainable=trainable,\n","                                       name='embedding')\n","        else:\n","            self.embedding = Embedding(input_dim=embeddings.shape[0],\n","                                       output_dim=embeddings.shape[1],\n","                                       trainable=trainable,\n","                                       embeddings_initializer=tf.keras.initializers.Constant(embeddings),\n","                                       # weights=[embeddings],\n","                                       name='embedding')\n","        self.conv = Conv1D(filters,\n","                           kernel_size,\n","                           padding='valid',\n","                           activation='relu',\n","                           strides=1)\n","        self.pool = GlobalMaxPooling1D()\n","        self.fc = Dense(output_dim, activation='softmax')\n","\n","    def build(self):\n","        x = self.input\n","        embedding = self.embedding(x)\n","        conv = self.conv(embedding)\n","        pool = self.pool(conv)\n","        y = self.fc(pool)\n","        return Model(inputs=x, outputs=y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"auhlTfsbF477"},"source":["models = [\n","    RNNModel,\n","    LSTMModel,\n","    CNNModel,\n","    CNNModel\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_BG3pF0nGIYQ"},"source":["### Train the models"]},{"cell_type":"code","metadata":{"id":"2A62IICsGUTw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604409207555,"user_tz":-540,"elapsed":241738,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"74302d66-fdbf-4dce-a45f-e7febbed3b0f"},"source":["model_path = 'models/model_{}'\n","embeddings = [None, None, None, wv]\n","batch_size = 128\n","epochs = 100\n","i = 0\n","for model, embedding in zip(models, embeddings):\n","    tf.keras.backend.clear_session()\n","    model = model(num_words, num_label, embeddings=embedding).build()\n","    model.compile(\n","        optimizer='adam',\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['acc']\n","    )\n","\n","    callbacks = [\n","        EarlyStopping(patience=3),\n","        ModelCheckpoint(model_path.format(i), save_best_only=True)\n","    ]\n","\n","    model.fit(\n","        x=x_train, y=y_train,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        validation_split=0.2,\n","        callbacks=callbacks,\n","        shuffle=True\n","    )\n","    i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6696 - acc: 0.5814INFO:tensorflow:Assets written to: models/model_0/assets\n","50/50 [==============================] - 20s 391ms/step - loss: 0.6696 - acc: 0.5814 - val_loss: 0.6423 - val_acc: 0.6331\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.3559 - acc: 0.8641INFO:tensorflow:Assets written to: models/model_0/assets\n","50/50 [==============================] - 19s 372ms/step - loss: 0.3559 - acc: 0.8641 - val_loss: 0.5793 - val_acc: 0.7200\n","Epoch 3/100\n","50/50 [==============================] - 17s 338ms/step - loss: 0.0606 - acc: 0.9841 - val_loss: 0.6690 - val_acc: 0.7344\n","Epoch 4/100\n","50/50 [==============================] - 17s 333ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.7113\n","Epoch 5/100\n","50/50 [==============================] - 17s 335ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7995 - val_acc: 0.7231\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.5595 - acc: 0.7089INFO:tensorflow:Assets written to: models/model_1/assets\n","50/50 [==============================] - 18s 364ms/step - loss: 0.5595 - acc: 0.7089 - val_loss: 0.4573 - val_acc: 0.7850\n","Epoch 2/100\n","50/50 [==============================] - 9s 172ms/step - loss: 0.2631 - acc: 0.8981 - val_loss: 0.4654 - val_acc: 0.8100\n","Epoch 3/100\n","50/50 [==============================] - 9s 170ms/step - loss: 0.1071 - acc: 0.9625 - val_loss: 0.5582 - val_acc: 0.7912\n","Epoch 4/100\n","50/50 [==============================] - 8s 169ms/step - loss: 0.0528 - acc: 0.9855 - val_loss: 0.7595 - val_acc: 0.7769\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6235 - acc: 0.6722INFO:tensorflow:Assets written to: models/model_2/assets\n","50/50 [==============================] - 9s 186ms/step - loss: 0.6235 - acc: 0.6722 - val_loss: 0.5498 - val_acc: 0.7400\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.4170 - acc: 0.8353INFO:tensorflow:Assets written to: models/model_2/assets\n","50/50 [==============================] - 9s 172ms/step - loss: 0.4170 - acc: 0.8353 - val_loss: 0.4357 - val_acc: 0.8087\n","Epoch 3/100\n","50/50 [==============================] - ETA: 0s - loss: 0.2298 - acc: 0.9261INFO:tensorflow:Assets written to: models/model_2/assets\n","50/50 [==============================] - 8s 167ms/step - loss: 0.2298 - acc: 0.9261 - val_loss: 0.3894 - val_acc: 0.8275\n","Epoch 4/100\n","50/50 [==============================] - 8s 158ms/step - loss: 0.0950 - acc: 0.9812 - val_loss: 0.4047 - val_acc: 0.8375\n","Epoch 5/100\n","50/50 [==============================] - 8s 151ms/step - loss: 0.0308 - acc: 0.9987 - val_loss: 0.4449 - val_acc: 0.8319\n","Epoch 6/100\n","50/50 [==============================] - 8s 154ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8288\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6186 - acc: 0.6747INFO:tensorflow:Assets written to: models/model_3/assets\n","50/50 [==============================] - 9s 173ms/step - loss: 0.6186 - acc: 0.6747 - val_loss: 0.5443 - val_acc: 0.7475\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.4098 - acc: 0.8367INFO:tensorflow:Assets written to: models/model_3/assets\n","50/50 [==============================] - 9s 172ms/step - loss: 0.4098 - acc: 0.8367 - val_loss: 0.4322 - val_acc: 0.8125\n","Epoch 3/100\n","50/50 [==============================] - ETA: 0s - loss: 0.2194 - acc: 0.9287INFO:tensorflow:Assets written to: models/model_3/assets\n","50/50 [==============================] - 9s 171ms/step - loss: 0.2194 - acc: 0.9287 - val_loss: 0.3932 - val_acc: 0.8263\n","Epoch 4/100\n","50/50 [==============================] - 8s 157ms/step - loss: 0.0889 - acc: 0.9833 - val_loss: 0.4148 - val_acc: 0.8250\n","Epoch 5/100\n","50/50 [==============================] - 8s 158ms/step - loss: 0.0281 - acc: 0.9986 - val_loss: 0.4549 - val_acc: 0.8175\n","Epoch 6/100\n","50/50 [==============================] - 8s 156ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4917 - val_acc: 0.8181\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XJ40Y895G4yh"},"source":["### Evaluate the models"]},{"cell_type":"code","metadata":{"id":"eKuUr5h4uwb8"},"source":["class InferenceAPI:\n","    \"\"\"A model API that generates output sequence.\n","\n","    Attributes:\n","        model: Model.\n","        vocab: language's vocabulary.\n","    \"\"\"\n","\n","    def __init__(self, model, vocab, preprocess):\n","        self.model = model\n","        self.vocab = vocab\n","        self.preprocess = preprocess\n","\n","    def predict_from_texts(self, texts):\n","        x = self.preprocess(texts)\n","        x = self.vocab.texts_to_sequences(x)\n","        return self.predict_from_sequences(x)\n","\n","    def predict_from_sequences(self, sequences):\n","        sequences = pad_sequences(sequences, truncating='post')\n","        y = self.model.predict(sequences)\n","        return np.argmax(y, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4meeU3cG9Lg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604409218904,"user_tz":-540,"elapsed":245890,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"a80bdb40-8aa3-43aa-f5c7-c570adb569be"},"source":["model_names = ['RNN', 'LSTM', 'CNN', 'CNN(wv)']\n","for i, model_name in enumerate(model_names):\n","    tf.keras.backend.clear_session()\n","    model = load_model(model_path.format(i))\n","    api = InferenceAPI(model, vocab, preprocess_dataset)\n","    y_pred = api.predict_from_sequences(x_test)\n","    print(model_name)\n","    print('precision\\t: {:.4f}'.format(precision_score(y_test, y_pred, average='binary')))\n","    print('recall\\t: {:.4f}'.format(recall_score(y_test, y_pred, average='binary')))\n","    print('f1\\t: {:.4f}'.format(f1_score(y_test, y_pred, average='binary')))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RNN\n","precision\t: 0.7519\n","recall\t: 0.6864\n","f1\t: 0.7177\n","\n","LSTM\n","precision\t: 0.7471\n","recall\t: 0.8908\n","f1\t: 0.8126\n","\n","CNN\n","precision\t: 0.8451\n","recall\t: 0.8417\n","f1\t: 0.8434\n","\n","CNN(wv)\n","precision\t: 0.8321\n","recall\t: 0.8687\n","f1\t: 0.8500\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_jS-zFeYOi0k"},"source":["# Fine-tune BERT for Text Classification with ktrain\n","\n","文量の都合上、書籍には含まれていませんが、東北大が公開している日本語のBERTをFine-tuneして文章分類をしてみましょう。現在では、BERTを使う場合、Huggingfaceの[Transformers](https://github.com/huggingface/transformers)というパッケージが使われることが多いですが、ここではよりシンプルに書ける[ktrain](https://github.com/amaiya/ktrain)を使ってみます。細かい設定はともかく、サクッと学習させたいときに便利です。"]},{"cell_type":"markdown","metadata":{"id":"Pg904nB9Otks"},"source":["## Setup\n","\n","MeCabとktrainをインストールします。MeCabはBERTのTokenizerの中で使われています。"]},{"cell_type":"code","metadata":{"id":"WKpl8Gh8Opeh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604478106045,"user_tz":-540,"elapsed":82205,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"41a13383-c97b-43b9-d117-52ddc7b0e684"},"source":["!apt install aptitude\n","!aptitude install mecab libmecab-dev -y\n","!pip install mecab-python3 fugashi ipadic\n","!pip install ktrain"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n","  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n","  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n","  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n","  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","Suggested packages:\n","  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n","  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n","  libwww-perl xapian-tools\n","The following NEW packages will be installed:\n","  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n","  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n","  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n","  libhttp-message-perl libio-html-perl libio-string-perl\n","  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n","  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","0 upgraded, 21 newly installed, 0 to remove and 11 not upgraded.\n","Need to get 3,877 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n","Fetched 3,877 kB in 0s (23.8 MB/s)\n","Selecting previously unselected package aptitude-common.\n","(Reading database ... 144628 files and directories currently installed.)\n","Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n","Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n","Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n","Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Selecting previously unselected package libcwidget3v5:amd64.\n","Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n","Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n","Selecting previously unselected package libxapian30:amd64.\n","Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n","Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Selecting previously unselected package aptitude.\n","Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n","Unpacking aptitude (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libhtml-tagset-perl.\n","Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n","Unpacking libhtml-tagset-perl (3.20-3) ...\n","Selecting previously unselected package liburi-perl.\n","Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n","Unpacking liburi-perl (1.73-1) ...\n","Selecting previously unselected package libhtml-parser-perl.\n","Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n","Unpacking libhtml-parser-perl (3.72-3build1) ...\n","Selecting previously unselected package libcgi-pm-perl.\n","Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n","Unpacking libcgi-pm-perl (4.38-1) ...\n","Selecting previously unselected package libfcgi-perl.\n","Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n","Unpacking libfcgi-perl (0.78-2build1) ...\n","Selecting previously unselected package libcgi-fast-perl.\n","Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n","Unpacking libcgi-fast-perl (1:2.13-1) ...\n","Selecting previously unselected package libsub-name-perl.\n","Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n","Unpacking libsub-name-perl (0.21-1build1) ...\n","Selecting previously unselected package libclass-accessor-perl.\n","Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n","Unpacking libclass-accessor-perl (0.51-1) ...\n","Selecting previously unselected package libencode-locale-perl.\n","Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n","Unpacking libencode-locale-perl (1.05-1) ...\n","Selecting previously unselected package libtimedate-perl.\n","Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n","Unpacking libtimedate-perl (2.3000-2) ...\n","Selecting previously unselected package libhttp-date-perl.\n","Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n","Unpacking libhttp-date-perl (6.02-1) ...\n","Selecting previously unselected package libio-html-perl.\n","Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n","Unpacking libio-html-perl (1.001-1) ...\n","Selecting previously unselected package liblwp-mediatypes-perl.\n","Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n","Unpacking liblwp-mediatypes-perl (6.02-1) ...\n","Selecting previously unselected package libhttp-message-perl.\n","Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n","Unpacking libhttp-message-perl (6.14-1) ...\n","Selecting previously unselected package libio-string-perl.\n","Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n","Unpacking libio-string-perl (1.08-3) ...\n","Selecting previously unselected package libparse-debianchangelog-perl.\n","Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n","Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhtml-tagset-perl (3.20-3) ...\n","Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Setting up libencode-locale-perl (1.05-1) ...\n","Setting up libtimedate-perl (2.3000-2) ...\n","Setting up libio-html-perl (1.001-1) ...\n","Setting up aptitude-common (0.8.10-6ubuntu1) ...\n","Setting up liblwp-mediatypes-perl (6.02-1) ...\n","Setting up liburi-perl (1.73-1) ...\n","Setting up libhtml-parser-perl (3.72-3build1) ...\n","Setting up libcgi-pm-perl (4.38-1) ...\n","Setting up libio-string-perl (1.08-3) ...\n","Setting up libsub-name-perl (0.21-1build1) ...\n","Setting up libfcgi-perl (0.78-2build1) ...\n","Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Setting up libclass-accessor-perl (0.51-1) ...\n","Setting up libhttp-date-perl (6.02-1) ...\n","Setting up libcgi-fast-perl (1:2.13-1) ...\n","Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhttp-message-perl (6.14-1) ...\n","Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n","Setting up aptitude (0.8.10-6ubuntu1) ...\n","update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","The following NEW packages will be installed:\n","  libmecab-dev libmecab2{a} mecab mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n","0 packages upgraded, 6 newly installed, 0 to remove and 11 not upgraded.\n","Need to get 16.9 MB of archives. After unpacking 222 MB will be used.\n","Get: 1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n","Get: 2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n","Get: 3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n","Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n","Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n","Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n","Fetched 16.9 MB in 0s (52.3 MB/s)\n","Selecting previously unselected package libmecab2:amd64.\n","(Reading database ... 145087 files and directories currently installed.)\n","Preparing to unpack .../0-libmecab2_0.996-5_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-5) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../1-libmecab-dev_0.996-5_amd64.deb ...\n","Unpacking libmecab-dev (0.996-5) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../2-mecab-utils_0.996-5_amd64.deb ...\n","Unpacking mecab-utils (0.996-5) ...\n","Selecting previously unselected package mecab-jumandic-utf8.\n","Preparing to unpack .../3-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-jumandic.\n","Preparing to unpack .../4-mecab-jumandic_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic (7.0-20130310-4) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../5-mecab_0.996-5_amd64.deb ...\n","Unpacking mecab (0.996-5) ...\n","Setting up libmecab2:amd64 (0.996-5) ...\n","Setting up mecab-utils (0.996-5) ...\n","Setting up libmecab-dev (0.996-5) ...\n","Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Compiling Juman dictionary for Mecab.\n","reading /usr/share/mecab/dic/juman/unk.def ... 37\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/Special.csv ... 158\n","reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n","reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n","reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n","reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n","reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n","reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n","reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n","reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n","reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n","reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n","reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n","reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n","reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n","reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n","reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/juman-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-5) ...\n","Setting up mecab-jumandic (7.0-20130310-4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","                            \n","Collecting mecab-python3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/6d/807491c94bd78c2641d0245155f3b40c000dc49757ec1d249080218661bc/mecab_python3-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.5MB)\n","\u001b[K     |████████████████████████████████| 3.5MB 6.4MB/s \n","\u001b[?25hCollecting fugashi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/0a/fb7946e8206709ff128c9eff0a4a6db679a6dd7082e034ad5bb35703f6bf/fugashi-1.0.5-cp36-cp36m-manylinux1_x86_64.whl (476kB)\n","\u001b[K     |████████████████████████████████| 481kB 39.5MB/s \n","\u001b[?25hCollecting ipadic\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/4e/c459f94d62a0bef89f866857bc51b9105aff236b83928618315b41a26b7b/ipadic-1.0.0.tar.gz (13.4MB)\n","\u001b[K     |████████████████████████████████| 13.4MB 241kB/s \n","\u001b[?25hBuilding wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-cp36-none-any.whl size=13556725 sha256=d4d9ddf9d4705c44e4aff783327c5a88a157b0940bd12991f8e22a8e8ff61b2d\n","  Stored in directory: /root/.cache/pip/wheels/ff/00/d1/0c094a0ce58a77199a0c5801f0ecf510c80f0ecbec27f07d2c\n","Successfully built ipadic\n","Installing collected packages: mecab-python3, fugashi, ipadic\n","Successfully installed fugashi-1.0.5 ipadic-1.0.0 mecab-python3-1.0.2\n","Collecting ktrain\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b4/a614efba8fe41ba3ba8ea9300aeceac4bdb3cdb41c4796b4515f490aa1cc/ktrain-0.23.2.tar.gz (25.3MB)\n","\u001b[K     |████████████████████████████████| 25.3MB 129kB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.22.2.post1)\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.1.3)\n","Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n","Collecting keras_bert>=0.86.0\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.17.0)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 35.8MB/s \n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n","Collecting cchardet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/e5/a0b9edd8664ea3b0d3270c451ebbf86655ed9fc4c3e4c45b9afae9c2e382/cchardet-2.1.7-cp36-cp36m-manylinux2010_x86_64.whl (263kB)\n","\u001b[K     |████████████████████████████████| 266kB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.5)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.1)\n","Collecting seqeval==0.0.19\n","  Downloading https://files.pythonhosted.org/packages/93/e5/b7705156a77f742cfe4fc6f22d0c71591edb2d243328dff2f8fc0f933ab6/seqeval-0.0.19.tar.gz\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.4)\n","Collecting transformers>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 41.9MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n","Collecting syntok\n","  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n","Collecting whoosh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n","\u001b[K     |████████████████████████████████| 471kB 38.7MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->ktrain) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->ktrain) (1.18.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n","Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.86.0->ktrain) (2.4.3)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->ktrain) (1.15.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n","Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.7.4.3)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (5.1.1)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->ktrain) (3.0.12)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 38.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->ktrain) (2019.12.20)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->ktrain) (3.12.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->ktrain) (0.7)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 36.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.1.0->ktrain) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 39.1MB/s \n","\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (50.3.2)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras_bert>=0.86.0->ktrain) (2.10.0)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.1.0->ktrain) (7.1.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Building wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ktrain: filename=ktrain-0.23.2-cp36-none-any.whl size=25272006 sha256=913509d50c8de218986e352e5a2616a4805f777e26d8355220051e40429b888d\n","  Stored in directory: /root/.cache/pip/wheels/fe/4a/b1/aff404c4e0893ca1c0b64781d0298b7ff6de94d5117a0e7d5c\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=890525e115f01a119dd02f21e757f0b103855844ec7a33a6333b2f2eda3fe075\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=6ac10f653b24fb55399daba200db0f8da7cafbb5f4a7c41268733f867250f487\n","  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.19-cp36-none-any.whl size=9919 sha256=2da8d56ee276d50f9d0c7c8f27b894c443f6afbf4510a88e7c87059583e30ac2\n","  Stored in directory: /root/.cache/pip/wheels/8d/1f/bf/1198beceed805a2099060975f6281d1b01046dd279e19c97be\n","  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20919 sha256=f64a91c3504e87af8335b705e96b2f9835587c8d224aa804e3c9565dcb92d80f\n","  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=2a095387c1a59f38a89146b99a39ba1d6dc7f6b4e95d2023c3a138356e0f4a3d\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=db091e8d4045a999c7ac5529c4adf01539e23ff40b9eeb956658f8c7b9e85bac\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=0c1aa669f6f6c4579e8721f32268fb201c4c6a37d9321a5ea81f17274a2cddda\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=684d47380d1544fd52a1eae1724df602b0fb859af62011162a29e32ba2bbb2cc\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=f732d7be322fac9fdafad041230d82ff3873acd8d2661d802fe4441c5e62fb43\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=665089d9302f5e41f1d0ab7dedd42a77d3e6b1664b2b9b37471bce71d824a826\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=e741252c17b62f7aa0d7aec0d17e4aa06a03ee60cf6a7772376936e3072d2367\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=36d48a096f1950439af75b49078a2d5b9293c449066de7352d2499d8787ec937\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built ktrain keras-bert langdetect seqeval syntok keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, tokenizers, sentencepiece, sacremoses, transformers, syntok, whoosh, ktrain\n","Successfully installed cchardet-2.1.7 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.23.2 langdetect-1.0.8 sacremoses-0.0.43 sentencepiece-0.1.94 seqeval-0.0.19 syntok-1.3.1 tokenizers-0.9.2 transformers-3.4.0 whoosh-2.7.4\n","  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rHqwZJppPkjV"},"source":["### Hyper-parameters"]},{"cell_type":"code","metadata":{"id":"502K8VkHPml9"},"source":["maxlen = 300\n","lr = 2e-5\n","epochs = 2\n","MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEicJMpxPEap"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"XxoQyajNOrr_"},"source":["import ktrain\n","from ktrain import text\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4WT1GGbPZuM"},"source":["## The dataset"]},{"cell_type":"markdown","metadata":{"id":"nA2nJi8UPb12"},"source":["### Preprocess the dataset\n","\n","前処理としては、HTMLタグの除去とテキストをBERTに入力できる形式に変換しています。`text.Transformer`を使うことで、HuggingfaceのTransformersをラップして利用することができます。"]},{"cell_type":"code","metadata":{"id":"AqBzZVJdPavh"},"source":["x = [clean_html(text) for text in x]\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBgVhD4HPwLl","colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["29b19a3346fa4dd4a7bb38019f68c9e1","805aa5e2b54b47d3a6bc8623e574a537","7a53b67a544a4c0c97e73aac5421a765","8c3aa17454d84735a7e6ce14f597cb87","fb65578483cc40759b7142dfcbbb59a0","4c1a33d021be47c5b1523f779eb883ad","8c6879b35a914dcab1eb86d37afeab5b","2702df0925684744a797675858e5ccea","42e909f5e7b74256943e41efa2e81121","afe43cd045ee4073989772209638ffd3","9c96aea443b141b59c3291d8fd7294c6","f3b0fb87c01b4019a2446275824b5291","d53bf36fc58e44ebb4a0be781f2d5101","045b231a90a0481ea801d2b912c2881b","da695a6594b74efc9a251da947950ae7","b0a5036ea5d542a28a5db4ed4f8cb2bf"]},"executionInfo":{"status":"ok","timestamp":1604478149823,"user_tz":-540,"elapsed":12085,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"cf225744-78cf-4132-ceef-cd5e8d54df17"},"source":["classes = list(set(y_train))\n","t = text.Transformer(MODEL_NAME, maxlen=maxlen, class_names=classes)\n","trn = t.preprocess_train(x_train, y_train)\n","val = t.preprocess_train(x_val, y_val)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29b19a3346fa4dd4a7bb38019f68c9e1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","preprocessing train...\n","language: ja\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42e909f5e7b74256943e41efa2e81121","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Is Multi-Label? False\n","preprocessing train...\n","language: ja\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Is Multi-Label? False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t25BZH57P0zv"},"source":["## The models"]},{"cell_type":"markdown","metadata":{"id":"Oo2utsr7P3mc"},"source":["### Build the model"]},{"cell_type":"code","metadata":{"id":"YAtpT3ecP2T9","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a4dbea13effa4c13a4b710ac6de5d756","bff74540d6dd49d8a7e1765b25f00264","59ca4fbc8ec84e968fe5b325ced021ea","6e136d2fda5b404383fe06704e65001f","599900a96f0444bbb86de5e575aca1b4","af80f911e42249c0bd38b83c71f59b87","5cc588537ba3409082b2beb383aef7b5","2109d4004fa34b16bf4670d07bf8f7b3"]},"executionInfo":{"status":"ok","timestamp":1604478178376,"user_tz":-540,"elapsed":24748,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"5a078326-ebfd-48fc-ecf8-7b14da901149"},"source":["model = t.get_classifier()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4dbea13effa4c13a4b710ac6de5d756","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=545149952.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9AShqIcBP7Iu"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"ZkTE27OpP8Kt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604479837047,"user_tz":-540,"elapsed":1656565,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"1418f82c-cb15-4178-bc77-acb3d64f8b13"},"source":["learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=8)\n","learner.fit_onecycle(lr, epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","begin training using onecycle policy with max lr of 2e-05...\n","Epoch 1/2\n","750/750 [==============================] - 815s 1s/step - loss: 0.4033 - accuracy: 0.8153 - val_loss: 0.3108 - val_accuracy: 0.8820\n","Epoch 2/2\n","750/750 [==============================] - 814s 1s/step - loss: 0.2030 - accuracy: 0.9302 - val_loss: 0.2744 - val_accuracy: 0.8975\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe9fef1c0b8>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"15ndSHZCQMyo"},"source":["### Evaluate the model"]},{"cell_type":"code","metadata":{"id":"SfBp_H2sQN9K"},"source":["predictor = ktrain.get_predictor(learner.model, preproc=t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nUFdfk2QSX-"},"source":["y_pred = predictor.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RfGwtykQVcf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604479936505,"user_tz":-540,"elapsed":1146,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"a48e0424-6600-486e-d5d0-69b3076df07f"},"source":["print(classification_report(y_test, y_pred, digits=4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.9119    0.9092    0.9105      1002\n","           1     0.9091    0.9118    0.9105       998\n","\n","    accuracy                         0.9105      2000\n","   macro avg     0.9105    0.9105    0.9105      2000\n","weighted avg     0.9105    0.9105    0.9105      2000\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VS1yhTMiQmiX"},"source":["### Save and Load the model"]},{"cell_type":"code","metadata":{"id":"VJEAiPa2Qop2"},"source":["predictor.save('/tmp/model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CkONIzxQs7C"},"source":["reloaded_predictor = ktrain.load_predictor('/tmp/model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hx9uZY4cehM8","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1604480287448,"user_tz":-540,"elapsed":1171,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"96954fd8-1323-494c-bbe7-9affb49b205f"},"source":["x_test[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'この映画は「観る」というよりは、「眺める」ほうが向いている作品です。なんといっても内容がつまらないですこの監督は人間よりも犬の方が好きなんだなあと思いました。関係ないですが映像をほめているのになぜ１つ星かというと・・・映像のきれいさなんていうのは、技術とともに上がってくるものなので、いまはこの映像はきれいだなあなんて感心してしまいますが、何年かたったら、まあまあじゃないってなくらいになってるんじゃないかなあ、、でも映画の内容が良ければ、いつの時代でも見れますものね、、ってなわけで１です'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"1QDFb1RGQ1n1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604480292602,"user_tz":-540,"elapsed":928,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"007d0ec2-3f69-4357-9e4d-0ac2081a8025"},"source":["reloaded_predictor.predict(x_test[1])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"2G18DO24TsIn"},"source":["# Text Classification with Universal Sentence Encoder on TensorFlow Hub\n","\n","この例では、[TensorFlow Hub](https://tfhub.dev/)を使って文書分類をしてみましょう。TensorFlow Hubとは何かというと、機械学習モデルのリポジトリです。より噛み砕いて言うと、画像分類やテキスト分類、音声認識といったタスクに使うことのできる学習済みのモデルが置いてある場所です。TensorFlow Hubから学習済みのモデルをダウンロードすることで、そのモデルを基に自分のモデルを構築することができます。\n","\n","今回は、文書分類のために、Multilingual Universal Sentence Encoder(m-USE)と呼ばれるモデルを利用することにしましょう。m-USEを使うことで、多言語の文表現を得られます。モデルの詳細は以下から確認することができます。\n","\n","- [Multilingual Universal Sentence Encoder | TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3)"]},{"cell_type":"markdown","metadata":{"id":"XqGV9OMYTydo"},"source":["## Setup\n","\n","m-USEは、入力の処理を[TensorFlow Text](https://github.com/tensorflow/text)に依存しています。そのため、事前にTensorFlow Textをインストールしておく必要があります。"]},{"cell_type":"code","metadata":{"id":"1lkkK2t5efGK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604628482655,"user_tz":-540,"elapsed":3328,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"bd19342f-6703-4a2f-b475-8fb0b2baea63"},"source":["!pip install tensorflow-text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-text\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text) (2.3.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.10.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.15.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.35.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.12.1)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.3.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.33.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.1.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.6.3)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.4.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.3.3)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.3.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.2.0)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.18.5)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.10.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.4.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (4.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.4.0)\n","Installing collected packages: tensorflow-text\n","Successfully installed tensorflow-text-2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s35ZvCLeT79V"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"qYOf0IcGT30d"},"source":["import string\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_text as text\n","import tensorflow_hub as hub\n","from bs4 import BeautifulSoup\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.models import load_model, Model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lqx1xSxOUAxB"},"source":["### Resource\n","\n","TensorFlow Hubを使って、m-USEをKerasのレイヤーとしてロードします。`trainable`パラメータによって、学習する際に重みを更新するか否かを決定します。今回はm-USEの重みも更新することにします。"]},{"cell_type":"code","metadata":{"id":"AI1gWP0XT-ZA"},"source":["model_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3'\n","use_layer = hub.KerasLayer(model_url, trainable=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CAadnQTfUGZ1"},"source":["## The dataset"]},{"cell_type":"markdown","metadata":{"id":"k9XJ6RAMUIXI"},"source":["### Preprocess the dataset\n","\n","前処理としては以下の2つを行います。\n","- HTMLの除去\n","- テキストの切り詰め\n","\n","本来はトークン数でテキストを切り詰めるべきだと思いますが、今回は文字数で切り詰めてしまいます。m-USEのインターフェースの都合上、トークン数で切り詰めるのが容易ではなさそうなためです。"]},{"cell_type":"code","metadata":{"id":"jJxXS99lUDJb"},"source":["x = [clean_html(text) for text in x]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3inF4mutUNhK"},"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xyMq-BiuUPvC"},"source":["def create_input(input_strings, max_seq_length):\n","    input_texts = [text[:max_seq_length] for text in input_strings]\n","    return input_texts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yk0pMoLfURdy"},"source":["max_seq_length = 300\n","train_inputs = create_input(x_train, max_seq_length=max_seq_length)\n","validation_inputs = create_input(x_test, max_seq_length=max_seq_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJ6LPgndUTWJ"},"source":["## The model"]},{"cell_type":"markdown","metadata":{"id":"-S-tH8yiUVSK"},"source":["### Build the model"]},{"cell_type":"code","metadata":{"id":"m2mbxpaRUUW2"},"source":["def get_model(use_layer, num_labels, rate=0.1):\n","    input_strings = tf.keras.layers.Input(shape=[], dtype=tf.string)\n","    pooled_output = use_layer(input_strings)\n","    pooled_output = tf.keras.layers.Dropout(rate=rate)(pooled_output)\n","    output = tf.keras.layers.Dense(units=num_labels, activation='softmax')(pooled_output)\n","\n","    return tf.keras.Model(\n","                inputs=[input_strings],\n","                outputs=output\n","            )\n","\n","\n","num_labels = 2\n","model = get_model(\n","    use_layer,\n","    num_labels=num_labels\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlI3TPGFUZZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604628979302,"user_tz":-540,"elapsed":4225,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"0727231e-f240-4aee-94f7-7431aba90d3b"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None,)]                 0         \n","_________________________________________________________________\n","keras_layer (KerasLayer)     (None, 512)               85213184  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 1026      \n","=================================================================\n","Total params: 85,214,210\n","Trainable params: 85,214,210\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nMFWzIPWUeIx"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"fD_pqJDHUbX8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604630223946,"user_tz":-540,"elapsed":1248866,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"111469f0-fda1-43db-f27d-b3a2f4a9132b"},"source":["epochs = 100\n","batch_size = 16\n","save_path = '/tmp/model'\n","\n","model.compile(\n","    optimizer='sgd',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.fit(\n","      x=np.array(train_inputs), y=y_train,\n","      validation_split=0.2,\n","      epochs=epochs,\n","      callbacks=[\n","                 tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n","                 tf.keras.callbacks.ModelCheckpoint(\n","                     filepath=save_path,\n","                     monitor='val_loss',\n","                     save_best_only=True,\n","                     mode='min'\n","                 )\n","      ],\n","      shuffle=True\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["200/200 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.5569WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 357ms/step - loss: 0.6866 - accuracy: 0.5569 - val_loss: 0.6784 - val_accuracy: 0.6100\n","Epoch 2/100\n","200/200 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6492INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 70s 350ms/step - loss: 0.6695 - accuracy: 0.6492 - val_loss: 0.6620 - val_accuracy: 0.6625\n","Epoch 3/100\n","200/200 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6853INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 70s 352ms/step - loss: 0.6512 - accuracy: 0.6853 - val_loss: 0.6438 - val_accuracy: 0.6881\n","Epoch 4/100\n","200/200 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.7070INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 353ms/step - loss: 0.6308 - accuracy: 0.7070 - val_loss: 0.6225 - val_accuracy: 0.7000\n","Epoch 5/100\n","200/200 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7220INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 354ms/step - loss: 0.6064 - accuracy: 0.7220 - val_loss: 0.5958 - val_accuracy: 0.7156\n","Epoch 6/100\n","200/200 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.7473INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 356ms/step - loss: 0.5743 - accuracy: 0.7473 - val_loss: 0.5600 - val_accuracy: 0.7437\n","Epoch 7/100\n","200/200 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.7811INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 354ms/step - loss: 0.5325 - accuracy: 0.7811 - val_loss: 0.5139 - val_accuracy: 0.7756\n","Epoch 8/100\n","200/200 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.8023INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 354ms/step - loss: 0.4847 - accuracy: 0.8023 - val_loss: 0.4702 - val_accuracy: 0.7969\n","Epoch 9/100\n","200/200 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.8216INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 353ms/step - loss: 0.4420 - accuracy: 0.8216 - val_loss: 0.4387 - val_accuracy: 0.8163\n","Epoch 10/100\n","200/200 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8348INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 354ms/step - loss: 0.4114 - accuracy: 0.8348 - val_loss: 0.4266 - val_accuracy: 0.8225\n","Epoch 11/100\n","200/200 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8447INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 70s 352ms/step - loss: 0.3891 - accuracy: 0.8447 - val_loss: 0.4189 - val_accuracy: 0.8194\n","Epoch 12/100\n","200/200 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8536INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 353ms/step - loss: 0.3706 - accuracy: 0.8536 - val_loss: 0.4084 - val_accuracy: 0.8225\n","Epoch 13/100\n","200/200 [==============================] - 45s 226ms/step - loss: 0.3535 - accuracy: 0.8622 - val_loss: 0.4088 - val_accuracy: 0.8281\n","Epoch 14/100\n","200/200 [==============================] - 46s 229ms/step - loss: 0.3360 - accuracy: 0.8719 - val_loss: 0.4195 - val_accuracy: 0.8144\n","Epoch 15/100\n","200/200 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8786INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 72s 359ms/step - loss: 0.3218 - accuracy: 0.8786 - val_loss: 0.4021 - val_accuracy: 0.8281\n","Epoch 16/100\n","200/200 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8911INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200/200 [==============================] - 71s 356ms/step - loss: 0.3027 - accuracy: 0.8911 - val_loss: 0.4010 - val_accuracy: 0.8331\n","Epoch 17/100\n","200/200 [==============================] - 45s 226ms/step - loss: 0.2862 - accuracy: 0.8989 - val_loss: 0.4044 - val_accuracy: 0.8263\n","Epoch 18/100\n","200/200 [==============================] - 46s 229ms/step - loss: 0.2727 - accuracy: 0.9030 - val_loss: 0.4042 - val_accuracy: 0.8344\n","Epoch 19/100\n","200/200 [==============================] - 46s 231ms/step - loss: 0.2579 - accuracy: 0.9133 - val_loss: 0.4077 - val_accuracy: 0.8369\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa01ae0d588>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"lYCETIT-Uhnh"},"source":["### Load the trained model"]},{"cell_type":"code","metadata":{"id":"a6eckcwqUfR8"},"source":["model = load_model(save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"feDC9xi7UlBI"},"source":["### Evaluate the model"]},{"cell_type":"code","metadata":{"id":"35kxg_2tUjjI"},"source":["y_pred = model.predict(validation_inputs, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLSjU0JBUoyl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604630255017,"user_tz":-540,"elapsed":1279930,"user":{"displayName":"Hiroki Nakayama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCsuu6UPzhyvNb9Oq7ud4e3-_dZ4LNQOTDJ8Md=s64","userId":"12329911095310806541"}},"outputId":"fc45bd58-288d-4ef1-f85a-82d598868df0"},"source":["print(classification_report(y_test, np.argmax(y_pred, axis=-1), digits=4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.8437    0.8403    0.8420      1002\n","           1     0.8403    0.8437    0.8420       998\n","\n","    accuracy                         0.8420      2000\n","   macro avg     0.8420    0.8420    0.8420      2000\n","weighted avg     0.8420    0.8420    0.8420      2000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"skeCI5M7UpFs"},"source":[""],"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_named_entity_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8f2083154e94f81bd26411ac0deb5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ddc558b08124799a2d1977c9802f928",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_415ea5f449434bd9b5f8af6807bda5ba",
              "IPY_MODEL_2d703c78cabb45a480fc4f088dbced98"
            ]
          }
        },
        "3ddc558b08124799a2d1977c9802f928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "415ea5f449434bd9b5f8af6807bda5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7bb5b6180fea46868644ed4d532524ac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 257706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 257706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4808ea701374d638036ab284d4ec0e8"
          }
        },
        "2d703c78cabb45a480fc4f088dbced98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8803012f37734646b99b47a84a3c94a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 258k/258k [00:00&lt;00:00, 3.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88684a76f8004b4a9c522aef2bbc1d7a"
          }
        },
        "7bb5b6180fea46868644ed4d532524ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4808ea701374d638036ab284d4ec0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8803012f37734646b99b47a84a3c94a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88684a76f8004b4a9c522aef2bbc1d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3366c41e23e4b57b2c50f9b114c1014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a6782f2a4f84dd6a93bc52739d6adc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e1f42e4a2db4a8bb1ace8c25f946268",
              "IPY_MODEL_372e666ae8464cc3a59ccc0fefa84dd5"
            ]
          }
        },
        "1a6782f2a4f84dd6a93bc52739d6adc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e1f42e4a2db4a8bb1ace8c25f946268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ba28328a622464496a46f7264378057",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a69797d34fa04f4e9fe019b7f2d1e924"
          }
        },
        "372e666ae8464cc3a59ccc0fefa84dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e716c17ba4c74be6b8e0112f5d57b167",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 479/479 [00:00&lt;00:00, 1.09kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccacd145a49b483e8b54566ddde0c493"
          }
        },
        "1ba28328a622464496a46f7264378057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a69797d34fa04f4e9fe019b7f2d1e924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e716c17ba4c74be6b8e0112f5d57b167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccacd145a49b483e8b54566ddde0c493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d759ddaf8ad44fca913bf7d974872b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0dfb3e54bfc460993ae5453461f39e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b95d70ccf05463189ce5169d282c5de",
              "IPY_MODEL_1a630de163394134983492eee01dfc71"
            ]
          }
        },
        "a0dfb3e54bfc460993ae5453461f39e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b95d70ccf05463189ce5169d282c5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36996acbc136472e92dc0ffb1e2d993e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 545149952,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 545149952,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eccce64633614524a3813ccd26c455da"
          }
        },
        "1a630de163394134983492eee01dfc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67965ca473124576b5bc04cb7fea91bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 545M/545M [00:11&lt;00:00, 49.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b75c9bd11914ba291e72251d3908a7c"
          }
        },
        "36996acbc136472e92dc0ffb1e2d993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eccce64633614524a3813ccd26c455da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67965ca473124576b5bc04cb7fea91bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b75c9bd11914ba291e72251d3908a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amplil/nlp-introduction/blob/main/10_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy7zVGAsDj7t"
      },
      "source": [
        "# Named Entity Recognition using Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6kLbNONDFsQ"
      },
      "source": [
        "## History\n",
        "\n",
        "### 2020/9/3\n",
        "\n",
        "I fixed some issues. Sorry for the inconvenience.\n",
        "\n",
        "- Change the name of pre-trained BERT model(bert-base-japanese-whole-word-masking -> cl-tohoku/bert-base-japanese-whole-word-masking)\n",
        "- Update `evaluate` function due to the version upgrade of Transformers(v2.3.0 -> v3.1.0)\n",
        "- Fix the version of transformers(v3.1.0)\n",
        "- Reduce the `batch_size` from 32 to 16 due to OOM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do805zSlwTue"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpwshrgrwBsn"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3pSBNlZwGFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3005447-0573-4f8a-8eb1-160b24172c41"
      },
      "source": [
        "!pip install seqeval transformers==3.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting transformers==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 48.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (8.0.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=c60d521c1ba1dc5dd51ce2d69d779596eefbb6ff9b9970e77ea9c8bddd03d661\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval, sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 seqeval-1.2.2 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY7mEyiqwXw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d63996-7875-4030-b2b1-8c2cd2ae7e85"
      },
      "source": [
        "!mkdir data\n",
        "!mkdir models\n",
        "!wget https://raw.githubusercontent.com/Hironsan/IOB2Corpus/master/ja.wikipedia.conll -P data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-19 09:00:48--  https://raw.githubusercontent.com/Hironsan/IOB2Corpus/master/ja.wikipedia.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1297592 (1.2M) [text/plain]\n",
            "Saving to: ‘data/ja.wikipedia.conll’\n",
            "\n",
            "\rja.wikipedia.conll    0%[                    ]       0  --.-KB/s               \rja.wikipedia.conll  100%[===================>]   1.24M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-19 09:00:48 (41.1 MB/s) - ‘data/ja.wikipedia.conll’ saved [1297592/1297592]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENlcEzF6EyJC"
      },
      "source": [
        "### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdxgZBQKE0ac"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "num_words = 15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8NdO0U1D7Zr"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8cds7mUD9RL"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from seqeval.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7GSLaHewmV2"
      },
      "source": [
        "## The dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcW-2LArE_hT"
      },
      "source": [
        "### Load the [ja.wikipedia.conll](https://github.com/Hironsan/IOB2Corpus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVaLQ4f4wkNh"
      },
      "source": [
        "def load_dataset(filename, encoding='utf-8'):\n",
        "    \"\"\"Loads data and label from a file.\n",
        "    Args:\n",
        "        filename (str): path to the file.\n",
        "        encoding (str): file encoding format.\n",
        "        The file format is tab-separated values.\n",
        "        A blank line is required at the end of a sentence.\n",
        "        For example:\n",
        "        ```\n",
        "        EU\tB-ORG\n",
        "        rejects\tO\n",
        "        German\tB-MISC\n",
        "        call\tO\n",
        "        to\tO\n",
        "        boycott\tO\n",
        "        British\tB-MISC\n",
        "        lamb\tO\n",
        "        .\tO\n",
        "        Peter\tB-PER\n",
        "        Blackburn\tI-PER\n",
        "        ...\n",
        "        ```\n",
        "    Returns:\n",
        "        tuple(numpy array, numpy array): data and labels.\n",
        "    Example:\n",
        "        >>> filename = 'conll2003/en/ner/train.txt'\n",
        "        >>> data, labels = load_data_and_labels(filename)\n",
        "    \"\"\"\n",
        "    sents, labels = [], []\n",
        "    words, tags = [], []\n",
        "    with open(filename, encoding=encoding) as f:\n",
        "        for line in f:\n",
        "            line = line.rstrip()\n",
        "            if line:\n",
        "                word, tag = line.split('\\t')\n",
        "                words.append(word)\n",
        "                tags.append(tag)\n",
        "            else:\n",
        "                sents.append(words)\n",
        "                labels.append(tags)\n",
        "                words, tags = [], []\n",
        "        if words:\n",
        "            sents.append(words)\n",
        "            labels.append(tags)\n",
        "\n",
        "    return sents, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBjjGh7XFVzW"
      },
      "source": [
        "x, y = load_dataset('./data/ja.wikipedia.conll')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIl_MoqCwqAu"
      },
      "source": [
        "### Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBb1bBB4wpUR"
      },
      "source": [
        "class Vocab:\n",
        "\n",
        "    def __init__(self, num_words=None, lower=True, oov_token=None):\n",
        "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "            num_words=num_words,\n",
        "            oov_token=oov_token,\n",
        "            filters='',\n",
        "            lower=lower,\n",
        "            split='\\t'\n",
        "        )\n",
        "\n",
        "    def fit(self, sequences):\n",
        "        texts = self._texts(sequences)\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "        return self\n",
        "\n",
        "    def encode(self, sequences):\n",
        "        texts = self._texts(sequences)\n",
        "        return self.tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    def decode(self, sequences):\n",
        "        texts = self.tokenizer.sequences_to_texts(sequences)\n",
        "        return [text.split(' ') for text in texts]\n",
        "\n",
        "    def _texts(self, sequences):\n",
        "        return ['\\t'.join(words) for words in sequences]\n",
        "\n",
        "    def get_index(self, word):\n",
        "        return self.tokenizer.word_index.get(word)\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        \"\"\"Return vocabulary size.\"\"\"\n",
        "        return len(self.tokenizer.word_index) + 1\n",
        "\n",
        "    def save(self, file_path):\n",
        "        with open(file_path, 'w') as f:\n",
        "            config = self.tokenizer.to_json()\n",
        "            f.write(config)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_path):\n",
        "        with open(file_path) as f:\n",
        "            tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f.read())\n",
        "            vocab = cls()\n",
        "            vocab.tokenizer = tokenizer\n",
        "        return vocab\n",
        "\n",
        "\n",
        "def normalize_number(text, reduce=True):\n",
        "    if reduce:\n",
        "        normalized_text = re.sub(r'\\d+', '0', text)\n",
        "    else:\n",
        "        normalized_text = re.sub(r'\\d', '0', text)\n",
        "    return normalized_text\n",
        "\n",
        "\n",
        "def preprocess_dataset(sequences):\n",
        "    sequences = [[normalize_number(w) for w in words] for words in sequences]\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def create_dataset(sequences, vocab):\n",
        "    sequences = vocab.encode(sequences)\n",
        "    sequences = pad_sequences(sequences, padding='post')\n",
        "    return sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPz6CyN4FjCo"
      },
      "source": [
        "x = preprocess_dataset(x)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "source_vocab = Vocab(num_words=num_words, oov_token='<UNK>').fit(x_train)\n",
        "target_vocab = Vocab(lower=False).fit(y_train)\n",
        "x_train = create_dataset(x_train, source_vocab)\n",
        "y_train = create_dataset(y_train, target_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDhcqeEKwwDg"
      },
      "source": [
        "## The models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdxL6fhIFth-"
      },
      "source": [
        "### Build the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2BAMgPuwuBU"
      },
      "source": [
        "class UnidirectionalModel:\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, emb_dim=100, hid_dim=100, embeddings=None):\n",
        "        self.input = Input(shape=(None,), name='input')\n",
        "        if embeddings is None:\n",
        "            self.embedding = Embedding(input_dim=input_dim,\n",
        "                                       output_dim=emb_dim,\n",
        "                                       mask_zero=True,\n",
        "                                       name='embedding')\n",
        "        else:\n",
        "            self.embedding = Embedding(input_dim=embeddings.shape[0],\n",
        "                                       output_dim=embeddings.shape[1],\n",
        "                                       mask_zero=True,\n",
        "                                       weights=[embeddings],\n",
        "                                       name='embedding')\n",
        "        self.lstm = LSTM(hid_dim,\n",
        "                         return_sequences=True,\n",
        "                         name='lstm')\n",
        "        self.fc = Dense(output_dim, activation='softmax')\n",
        "\n",
        "    def build(self):\n",
        "        x = self.input\n",
        "        embedding = self.embedding(x)\n",
        "        lstm = self.lstm(embedding)\n",
        "        y = self.fc(lstm)\n",
        "        return Model(inputs=x, outputs=y)\n",
        "\n",
        "\n",
        "class BidirectionalModel:\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, emb_dim=100, hid_dim=100, embeddings=None):\n",
        "        self.input = Input(shape=(None,), name='input')\n",
        "        if embeddings is None:\n",
        "            self.embedding = Embedding(input_dim=input_dim,\n",
        "                                       output_dim=emb_dim,\n",
        "                                       mask_zero=True,\n",
        "                                       name='embedding')\n",
        "        else:\n",
        "            self.embedding = Embedding(input_dim=embeddings.shape[0],\n",
        "                                       output_dim=embeddings.shape[1],\n",
        "                                       mask_zero=True,\n",
        "                                       weights=[embeddings],\n",
        "                                       name='embedding')\n",
        "        lstm = LSTM(hid_dim,\n",
        "                    return_sequences=True,\n",
        "                    name='lstm')\n",
        "        self.bilstm = Bidirectional(lstm, name='bilstm')\n",
        "        self.fc = Dense(output_dim, activation='softmax')\n",
        "\n",
        "    def build(self):\n",
        "        x = self.input\n",
        "        embedding = self.embedding(x)\n",
        "        lstm = self.bilstm(embedding)\n",
        "        y = self.fc(lstm)\n",
        "        return Model(inputs=x, outputs=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbSGjw-HHCB"
      },
      "source": [
        "models = [\n",
        "    UnidirectionalModel(num_words, target_vocab.size).build(),\n",
        "    BidirectionalModel(num_words, target_vocab.size).build(),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR64HT-ow1A8"
      },
      "source": [
        "### Train the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaAg99slHQCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a411e09-5935-4555-abf0-312ad513757e"
      },
      "source": [
        "model_path = 'models/model_{}'\n",
        "for i, model in enumerate(models):\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "    # Preparing callbacks.\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=3),\n",
        "        ModelCheckpoint(model_path.format(i), save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    # Train the model.\n",
        "    model.fit(x=x_train,\n",
        "              y=y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_split=0.1,\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 36s 103ms/step - loss: 1.8575 - val_loss: 0.7113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.6239 - val_loss: 0.6247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.5966 - val_loss: 0.6025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.5309 - val_loss: 0.5655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.5186 - val_loss: 0.5098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.4407 - val_loss: 0.4517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3883 - val_loss: 0.4140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.3349 - val_loss: 0.3878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2987 - val_loss: 0.3713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2746 - val_loss: 0.3549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2581 - val_loss: 0.3406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2455 - val_loss: 0.3374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.2286 - val_loss: 0.3264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2140 - val_loss: 0.3225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2004 - val_loss: 0.3175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1946 - val_loss: 0.3137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1803 - val_loss: 0.3174\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1855 - val_loss: 0.3152\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1788 - val_loss: 0.3100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1715 - val_loss: 0.3112\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1659 - val_loss: 0.3082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1532 - val_loss: 0.3120\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1432 - val_loss: 0.3028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1331 - val_loss: 0.3023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1203 - val_loss: 0.3017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_0/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.1210 - val_loss: 0.3109\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 37ms/step - loss: 0.1165 - val_loss: 0.3112\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 36ms/step - loss: 0.1028 - val_loss: 0.3152\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 10s 137ms/step - loss: 1.8109 - val_loss: 0.6794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.5851 - val_loss: 0.6090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.5840 - val_loss: 0.5737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.5091 - val_loss: 0.5106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4677 - val_loss: 0.4435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.3696 - val_loss: 0.4051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.3437 - val_loss: 0.3827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3013 - val_loss: 0.3617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.2836 - val_loss: 0.3426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.2552 - val_loss: 0.3308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.2343 - val_loss: 0.3153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.2132 - val_loss: 0.3061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.2011 - val_loss: 0.3063\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 44ms/step - loss: 0.1783 - val_loss: 0.2974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.1566 - val_loss: 0.2922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.1479 - val_loss: 0.2895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.1251 - val_loss: 0.2862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 47ms/step - loss: 0.1208 - val_loss: 0.2819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.0982 - val_loss: 0.2864\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0844 - val_loss: 0.2791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/model_1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 46ms/step - loss: 0.0704 - val_loss: 0.2800\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.0639 - val_loss: 0.2793\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.0518 - val_loss: 0.2859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWhT3Pu5HoTB"
      },
      "source": [
        "### Evaluate the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AlqMrRUw0bK"
      },
      "source": [
        "class InferenceAPI:\n",
        "    \"\"\"A model API that generates output sequence.\n",
        "\n",
        "    Attributes:\n",
        "        model: Model.\n",
        "        source_vocab: source language's vocabulary.\n",
        "        target_vocab: target language's vocabulary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, source_vocab, target_vocab):\n",
        "        self.model = model\n",
        "        self.source_vocab = source_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "\n",
        "    def predict_from_sequences(self, sequences):\n",
        "        lengths = map(len, sequences)\n",
        "        sequences = self.source_vocab.encode(sequences)\n",
        "        sequences = pad_sequences(sequences, padding='post')\n",
        "        y_pred = self.model.predict(sequences)\n",
        "        y_pred = np.argmax(y_pred, axis=-1)\n",
        "        y_pred = self.target_vocab.decode(y_pred)\n",
        "        y_pred = [y[:l] for y, l in zip(y_pred, lengths)]\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYBNwl2THxdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b63d19-a403-4097-8622-2cff6e46a375"
      },
      "source": [
        "model_names = ['Unidirectional Model', 'Bidirectional Model']\n",
        "for i, model_name in enumerate(model_names):\n",
        "    model = load_model(model_path.format(i))\n",
        "    api = InferenceAPI(model, source_vocab, target_vocab)\n",
        "    y_pred = api.predict_from_sequences(x_test)\n",
        "    y_pred = api.predict_from_sequences(x_test)\n",
        "    print(model_name)\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unidirectional Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARTIFACT     0.1182    0.0844    0.0985       154\n",
            "        DATE     0.4361    0.8444    0.5751       315\n",
            "       EVENT     0.0000    0.0000    0.0000        64\n",
            "    LOCATION     0.6610    0.5152    0.5791       526\n",
            "       MONEY     0.0000    0.0000    0.0000        12\n",
            "      NUMBER     0.0836    0.1284    0.1013       218\n",
            "ORGANIZATION     0.1489    0.1855    0.1652       248\n",
            "       OTHER     0.0000    0.0000    0.0000        75\n",
            "     PERCENT     0.0000    0.0000    0.0000        52\n",
            "      PERSON     0.2222    0.1250    0.1600       224\n",
            "        TIME     0.0000    0.0000    0.0000         5\n",
            "\n",
            "   micro avg     0.3399    0.3444    0.3422      1893\n",
            "   macro avg     0.1518    0.1712    0.1526      1893\n",
            "weighted avg     0.3213    0.3444    0.3169      1893\n",
            "\n",
            "\n",
            "Bidirectional Model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARTIFACT     0.1161    0.0844    0.0977       154\n",
            "        DATE     0.8121    0.8508    0.8310       315\n",
            "       EVENT     0.0000    0.0000    0.0000        64\n",
            "    LOCATION     0.5991    0.4886    0.5382       526\n",
            "       MONEY     0.2500    0.4167    0.3125        12\n",
            "      NUMBER     0.4618    0.6101    0.5257       218\n",
            "ORGANIZATION     0.2477    0.2137    0.2294       248\n",
            "       OTHER     0.0000    0.0000    0.0000        75\n",
            "     PERCENT     0.0303    0.0192    0.0235        52\n",
            "      PERSON     0.1284    0.0848    0.1022       224\n",
            "        TIME     0.0000    0.0000    0.0000         5\n",
            "\n",
            "   micro avg     0.4652    0.3957    0.4276      1893\n",
            "   macro avg     0.2405    0.2517    0.2418      1893\n",
            "weighted avg     0.4143    0.3957    0.4011      1893\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXs9ScuGJQ4D"
      },
      "source": [
        "# BERT for Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p73SZBhOJlsX"
      },
      "source": [
        "# utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff6Kroz9xAdr"
      },
      "source": [
        "def evaluate(model, target_vocab, features, labels):\n",
        "    label_ids = model.predict(features)[0]\n",
        "    label_ids = np.argmax(label_ids, axis=-1)\n",
        "    y_pred = [[] for _ in range(label_ids.shape[0])]\n",
        "    y_true = [[] for _ in range(label_ids.shape[0])]\n",
        "    for i in range(label_ids.shape[0]):\n",
        "        for j in range(label_ids.shape[1]):\n",
        "            if labels[i][j] == 0:\n",
        "                continue\n",
        "            y_pred[i].append(label_ids[i][j])\n",
        "            y_true[i].append(labels[i][j])\n",
        "    y_pred = target_vocab.decode(y_pred)\n",
        "    y_true = target_vocab.decode(y_true)\n",
        "    print(classification_report(y_true, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTp7bNRJ5b2"
      },
      "source": [
        "# preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFM1V_O-JeDo"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def convert_examples_to_features(x, y,\n",
        "                                 vocab,\n",
        "                                 max_seq_length,\n",
        "                                 tokenizer):\n",
        "    pad_token = 0\n",
        "    features = {\n",
        "        'input_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'token_type_ids': [],\n",
        "        'label_ids': []\n",
        "    }\n",
        "    for words, labels in zip(x, y):\n",
        "        tokens = [tokenizer.cls_token]\n",
        "        label_ids = [pad_token]\n",
        "        for word, label in zip(words, labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            label_id = vocab.get_index(label)\n",
        "            label_ids.extend([label_id] + [pad_token] * (len(word_tokens) - 1))\n",
        "        tokens += [tokenizer.sep_token]\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        token_type_ids = [pad_token] * max_seq_length\n",
        "\n",
        "        features['input_ids'].append(input_ids)\n",
        "        features['attention_mask'].append(attention_mask)\n",
        "        features['token_type_ids'].append(token_type_ids)\n",
        "        features['label_ids'].append(label_ids)\n",
        "\n",
        "    for name in features:\n",
        "        features[name] = pad_sequences(features[name], padding='post', maxlen=max_seq_length)\n",
        "\n",
        "    x = [features['input_ids'], features['attention_mask'], features['token_type_ids']]\n",
        "    y = features['label_ids']\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aWoB26OKC1Q"
      },
      "source": [
        "# model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uummx80GKBmK"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertForTokenClassification, BertConfig\n",
        "\n",
        "\n",
        "def build_model(pretrained_model_name_or_path, num_labels):\n",
        "    config = BertConfig.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "    model = TFBertForTokenClassification.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        config=config\n",
        "    )\n",
        "    model.layers[-1].activation = tf.keras.activations.softmax\n",
        "    return model\n",
        "\n",
        "\n",
        "def loss_func(num_labels):\n",
        "    loss_fct = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        input_mask = tf.not_equal(y_true, 0)\n",
        "        logits = tf.reshape(y_pred, (-1, num_labels))\n",
        "        active_loss = tf.reshape(input_mask, (-1,))\n",
        "        active_logits = tf.boolean_mask(logits, active_loss)\n",
        "        train_labels = tf.reshape(y_true, (-1,))\n",
        "        active_labels = tf.boolean_mask(train_labels, active_loss)\n",
        "        cross_entropy = loss_fct(active_labels, active_logits)\n",
        "        return cross_entropy\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eoGpMNKKnE"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRhPsGBMKICn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d8f2083154e94f81bd26411ac0deb5ce",
            "3ddc558b08124799a2d1977c9802f928",
            "415ea5f449434bd9b5f8af6807bda5ba",
            "2d703c78cabb45a480fc4f088dbced98",
            "7bb5b6180fea46868644ed4d532524ac",
            "d4808ea701374d638036ab284d4ec0e8",
            "8803012f37734646b99b47a84a3c94a5",
            "88684a76f8004b4a9c522aef2bbc1d7a",
            "d3366c41e23e4b57b2c50f9b114c1014",
            "1a6782f2a4f84dd6a93bc52739d6adc9",
            "4e1f42e4a2db4a8bb1ace8c25f946268",
            "372e666ae8464cc3a59ccc0fefa84dd5",
            "1ba28328a622464496a46f7264378057",
            "a69797d34fa04f4e9fe019b7f2d1e924",
            "e716c17ba4c74be6b8e0112f5d57b167",
            "ccacd145a49b483e8b54566ddde0c493",
            "d759ddaf8ad44fca913bf7d974872b2d",
            "a0dfb3e54bfc460993ae5453461f39e0",
            "4b95d70ccf05463189ce5169d282c5de",
            "1a630de163394134983492eee01dfc71",
            "36996acbc136472e92dc0ffb1e2d993e",
            "eccce64633614524a3813ccd26c455da",
            "67965ca473124576b5bc04cb7fea91bf",
            "9b75c9bd11914ba291e72251d3908a7c"
          ]
        },
        "outputId": "96461b6e-8ca2-4516-f6ba-86c14a15b495"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from transformers import BertJapaneseTokenizer\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Set hyper-parameters.\n",
        "    batch_size = 16\n",
        "    epochs = 100\n",
        "    model_path = 'models/'\n",
        "    pretrained_model_name_or_path = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "    maxlen = 250\n",
        "\n",
        "    # Data loading.\n",
        "    x, y = load_dataset('./data/ja.wikipedia.conll')\n",
        "    tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model_name_or_path, do_word_tokenize=False)\n",
        "\n",
        "    # Pre-processing.\n",
        "    x = preprocess_dataset(x)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    target_vocab = Vocab(lower=False).fit(y_train)\n",
        "    features_train, labels_train = convert_examples_to_features(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        target_vocab,\n",
        "        max_seq_length=maxlen,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    features_test, labels_test = convert_examples_to_features(\n",
        "        x_test,\n",
        "        y_test,\n",
        "        target_vocab,\n",
        "        max_seq_length=maxlen,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    # Build model.\n",
        "    model = build_model(pretrained_model_name_or_path, target_vocab.size)\n",
        "    model.compile(optimizer='sgd', loss=loss_func(target_vocab.size))\n",
        "\n",
        "    # Preparing callbacks.\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=3),\n",
        "    ]\n",
        "\n",
        "    # Train the model.\n",
        "    model.fit(x=features_train,\n",
        "              y=labels_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_split=0.1,\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)\n",
        "    model.save_pretrained(model_path)\n",
        "\n",
        "    # Evaluation.\n",
        "    evaluate(model, target_vocab, features_test, labels_test)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8f2083154e94f81bd26411ac0deb5ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3366c41e23e4b57b2c50f9b114c1014",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=479.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d759ddaf8ad44fca913bf7d974872b2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=545149952.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing TFBertForTokenClassification: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TFBertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier', 'dropout_37']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 51s 931ms/step - loss: 1.1704 - val_loss: 0.6621\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 39s 867ms/step - loss: 0.6339 - val_loss: 0.5558\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 39s 879ms/step - loss: 0.5297 - val_loss: 0.4998\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.4560 - val_loss: 0.4412\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.4068 - val_loss: 0.3963\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 39s 878ms/step - loss: 0.3710 - val_loss: 0.3706\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.3570 - val_loss: 0.3370\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 39s 875ms/step - loss: 0.3275 - val_loss: 0.3273\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.2795 - val_loss: 0.3030\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.2711 - val_loss: 0.2889\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.2652 - val_loss: 0.2812\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.2540 - val_loss: 0.2760\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.2295 - val_loss: 0.2689\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.2431 - val_loss: 0.2613\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 0.2284 - val_loss: 0.2561\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 0.2344 - val_loss: 0.2540\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.2076 - val_loss: 0.2448\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.2161 - val_loss: 0.2405\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.1905 - val_loss: 0.2433\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.2055 - val_loss: 0.2396\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.2156 - val_loss: 0.2372\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.1826 - val_loss: 0.2342\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.1707 - val_loss: 0.2305\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.1693 - val_loss: 0.2321\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 39s 877ms/step - loss: 0.1933 - val_loss: 0.2295\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.1767 - val_loss: 0.2320\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.1646 - val_loss: 0.2243\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 39s 876ms/step - loss: 0.1711 - val_loss: 0.2307\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 0.1609 - val_loss: 0.2254\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 39s 873ms/step - loss: 0.1753 - val_loss: 0.2232\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.1624 - val_loss: 0.2225\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.1636 - val_loss: 0.2244\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.1462 - val_loss: 0.2197\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 0.1514 - val_loss: 0.2238\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 0.1608 - val_loss: 0.2183\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 39s 873ms/step - loss: 0.1597 - val_loss: 0.2188\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 0.1412 - val_loss: 0.2152\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 39s 873ms/step - loss: 0.1585 - val_loss: 0.2211\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 39s 873ms/step - loss: 0.1384 - val_loss: 0.2158\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 0.1392 - val_loss: 0.2175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ARTIFACT     0.3077    0.3636    0.3333       154\n",
            "        DATE     0.7831    0.8254    0.8037       315\n",
            "       EVENT     0.4085    0.4531    0.4296        64\n",
            "    LOCATION     0.7767    0.7738    0.7752       526\n",
            "       MONEY     0.0000    0.0000    0.0000        12\n",
            "      NUMBER     0.4082    0.5505    0.4688       218\n",
            "ORGANIZATION     0.5503    0.6613    0.6007       248\n",
            "       OTHER     0.4500    0.3600    0.4000        75\n",
            "     PERCENT     0.0000    0.0000    0.0000        52\n",
            "      PERSON     0.8403    0.8929    0.8658       224\n",
            "        TIME     0.0000    0.0000    0.0000         5\n",
            "\n",
            "   micro avg     0.6188    0.6672    0.6421      1893\n",
            "   macro avg     0.4113    0.4437    0.4252      1893\n",
            "weighted avg     0.6213    0.6672    0.6418      1893\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wMu2NGaLIP2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}